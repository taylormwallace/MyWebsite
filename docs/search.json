{
  "articles": [
    {
      "path": "about.html",
      "title": "About this site",
      "description": "Some additional details about the website",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T11:51:15-08:00"
    },
    {
      "path": "index.html",
      "title": "Taylor Wallace",
      "author": [],
      "contents": "\r\n\r\n          \r\n          \r\n          Taylor Wallace\r\n          \r\n          \r\n          Home\r\n          Resume\r\n          \r\n          \r\n          Projects\r\n           \r\n          ▾\r\n          \r\n          \r\n          RSquared\r\n          Machine Learning\r\n          Final Project\r\n          \r\n          \r\n          \r\n          \r\n          \r\n          ☰\r\n          \r\n          \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Taylor Wallace\r\n            \r\n            \r\n              \r\n                \r\n                    \r\n                      \r\n                        LinkedIn\r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        Email\r\n                      \r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      \r\n                        GitHub\r\n                      \r\n                    \r\n                  \r\n                                  \r\n            \r\n          \r\n        \r\n        \r\n        \r\n          \r\n            I am currently working towards my Masters of Taxation at Mississippi State University. After graduation I will be starting my career as a Staff Accountant at LBMC in Nashville, TN. `\r\n          \r\n        \r\n      \r\n    \r\n\r\n    \r\n      \r\n        \r\n          \r\n            \r\n              \r\n            \r\n              Taylor Wallace\r\n            \r\n            \r\n              \r\n                \r\n                                    \r\n                    \r\n                      LinkedIn\r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      Email\r\n                    \r\n                  \r\n                                    \r\n                    \r\n                      GitHub\r\n                    \r\n                  \r\n                                  \r\n              \r\n            \r\n            \r\n              I am currently working towards my Masters of Taxation at Mississippi State University. After graduation I will be starting my career as a Staff Accountant at LBMC in Nashville, TN. `\r\n            \r\n        \r\n      \r\n    \r\n\r\n    \r\n    \r\n    ",
      "last_modified": "2021-12-06T11:49:32-08:00"
    },
    {
      "path": "K-nearest.html",
      "title": "Final Project",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nTaylor Wallace\r\n\r\n\r\nHome\r\nResume\r\n\r\n\r\nProjects\r\n \r\n▾\r\n\r\n\r\nRSquared\r\nMachine Learning\r\nFinal Project\r\n\r\n\r\n\r\n\r\n\r\n☰\r\n\r\n\r\n  \r\n    \r\n      \r\n        \r\n        \r\n        \r\n      \r\n      \r\n    \r\n    \r\n      \r\n  Home\r\n\r\n\r\n  Resume\r\n\r\n\r\n  \r\n    Projects\r\n     \r\n    \r\n  \r\n  \r\n      RSquared\r\n    \r\n    \r\n      Machine Learning\r\n    \r\n    \r\n      Final Project\r\n    \r\n  \r\n      \r\n  \r\n\r\n\r\n\r\n\r\n\r\n\r\nFinal Project\r\n\r\n\r\n\r\n\r\n\r\nRandom Forest\r\nThe data I have chosen is from the UCI Machine Learning Repository. It is a dataset that has different health characteristics of women from age 18-36 and if their fertility diagnosis was normal or altered. Variables include the season the test was done, age, childhood diseases, accidents or serious trauma, surgical intervention, high fevers within the past year, alcohol consumption, smoking habits, and number of hours spent sitting during the day.\r\nThis data shouldn’t be very skewed, but there could be some outliers. There may be instances where women have no underlying conditions and still can’t get pregnant for reasons not accounted for in this dataset or some may have all the underlying conditions shown and still be able to get pregnant.\r\nRandom Forest uses bagging and creates a set of decision trees for the dataset. Decision trees can classify instances. Each decision tree represents a question or an attribute and based on the instance’s “answer” to that question it will be classified as one thing or another. Random forest takes into consideration all the decision trees together instead of just looking at one.\r\nFor example in this dataset the instances will be classified as normal fertility or altered fertility based on the answers to the questions of the decision trees such as age, alcohol consumption, etc. The algorithm takes into account all the decision trees before making a decision on the classification. In the Output column N means normal and O means altered.\r\nset.seed(1)\r\n#lets split the data 60/40\r\nlibrary(caret)\r\ntrainIndex <- createDataPartition(fertility_Diagnosis$Output, p = .6, list = FALSE, times = 1)\r\n#grab the data\r\nFertilityTrain <- fertility_Diagnosis[ trainIndex,]\r\nFertilityTest  <- fertility_Diagnosis[-trainIndex,]\r\nThe model:\r\nset.seed(1)\r\n\r\nFertilityRF<- train(\r\n  form = factor(Output) ~ .,\r\n  data = FertilityTrain,\r\n  #here we add classProbs because we want probs\r\n  trControl = trainControl(method = \"cv\", number = 10,\r\n                           classProbs =  TRUE),\r\n  method = \"rf\",\r\n  tuneLength = 3)\r\n\r\nFertilityRF\r\n## Random Forest \r\n## \r\n## 61 samples\r\n##  9 predictor\r\n##  2 classes: 'N', 'O' \r\n## \r\n## No pre-processing\r\n## Resampling: Cross-Validated (10 fold) \r\n## Summary of sample sizes: 55, 56, 55, 54, 56, 55, ... \r\n## Resampling results across tuning parameters:\r\n## \r\n##   mtry  Accuracy   Kappa     \r\n##   2     0.8738095  0.10000000\r\n##   5     0.8371429  0.04126984\r\n##   9     0.8228571  0.02275132\r\n## \r\n## Accuracy was used to select the optimal model using the largest value.\r\n## The final value used for the model was mtry = 2.\r\nsummary(FertilityRF)\r\n##                 Length Class      Mode     \r\n## call               4   -none-     call     \r\n## type               1   -none-     character\r\n## predicted         61   factor     numeric  \r\n## err.rate        1500   -none-     numeric  \r\n## confusion          6   -none-     numeric  \r\n## votes            122   matrix     numeric  \r\n## oob.times         61   -none-     numeric  \r\n## classes            2   -none-     character\r\n## importance         9   -none-     numeric  \r\n## importanceSD       0   -none-     NULL     \r\n## localImportance    0   -none-     NULL     \r\n## proximity          0   -none-     NULL     \r\n## ntree              1   -none-     numeric  \r\n## mtry               1   -none-     numeric  \r\n## forest            14   -none-     list     \r\n## y                 61   factor     numeric  \r\n## test               0   -none-     NULL     \r\n## inbag              0   -none-     NULL     \r\n## xNames             9   -none-     character\r\n## problemType        1   -none-     character\r\n## tuneValue          1   data.frame list     \r\n## obsLevels          2   -none-     character\r\n## param              0   -none-     list\r\nFertilityRF_Pred<-predict(FertilityRF,FertilityTest,type=\"prob\")\r\n\r\nknitr::kable(FertilityRF_Pred)%>%\r\n  kableExtra::kable_styling(\"striped\")%>%\r\n  kableExtra::scroll_box(width = \"50%\",height=\"300px\")\r\n\r\n\r\n\r\n\r\nN\r\n\r\n\r\nO\r\n\r\n\r\n4\r\n\r\n\r\n0.942\r\n\r\n\r\n0.058\r\n\r\n\r\n5\r\n\r\n\r\n0.902\r\n\r\n\r\n0.098\r\n\r\n\r\n6\r\n\r\n\r\n0.616\r\n\r\n\r\n0.384\r\n\r\n\r\n7\r\n\r\n\r\n0.708\r\n\r\n\r\n0.292\r\n\r\n\r\n10\r\n\r\n\r\n0.994\r\n\r\n\r\n0.006\r\n\r\n\r\n11\r\n\r\n\r\n0.784\r\n\r\n\r\n0.216\r\n\r\n\r\n12\r\n\r\n\r\n0.884\r\n\r\n\r\n0.116\r\n\r\n\r\n14\r\n\r\n\r\n0.838\r\n\r\n\r\n0.162\r\n\r\n\r\n15\r\n\r\n\r\n0.812\r\n\r\n\r\n0.188\r\n\r\n\r\n17\r\n\r\n\r\n0.886\r\n\r\n\r\n0.114\r\n\r\n\r\n18\r\n\r\n\r\n0.722\r\n\r\n\r\n0.278\r\n\r\n\r\n19\r\n\r\n\r\n0.956\r\n\r\n\r\n0.044\r\n\r\n\r\n21\r\n\r\n\r\n0.682\r\n\r\n\r\n0.318\r\n\r\n\r\n23\r\n\r\n\r\n0.888\r\n\r\n\r\n0.112\r\n\r\n\r\n24\r\n\r\n\r\n0.710\r\n\r\n\r\n0.290\r\n\r\n\r\n28\r\n\r\n\r\n0.878\r\n\r\n\r\n0.122\r\n\r\n\r\n34\r\n\r\n\r\n0.864\r\n\r\n\r\n0.136\r\n\r\n\r\n35\r\n\r\n\r\n0.984\r\n\r\n\r\n0.016\r\n\r\n\r\n37\r\n\r\n\r\n0.912\r\n\r\n\r\n0.088\r\n\r\n\r\n38\r\n\r\n\r\n0.988\r\n\r\n\r\n0.012\r\n\r\n\r\n40\r\n\r\n\r\n0.960\r\n\r\n\r\n0.040\r\n\r\n\r\n45\r\n\r\n\r\n0.994\r\n\r\n\r\n0.006\r\n\r\n\r\n50\r\n\r\n\r\n0.980\r\n\r\n\r\n0.020\r\n\r\n\r\n55\r\n\r\n\r\n0.988\r\n\r\n\r\n0.012\r\n\r\n\r\n57\r\n\r\n\r\n0.938\r\n\r\n\r\n0.062\r\n\r\n\r\n58\r\n\r\n\r\n0.936\r\n\r\n\r\n0.064\r\n\r\n\r\n61\r\n\r\n\r\n0.806\r\n\r\n\r\n0.194\r\n\r\n\r\n64\r\n\r\n\r\n0.998\r\n\r\n\r\n0.002\r\n\r\n\r\n65\r\n\r\n\r\n0.986\r\n\r\n\r\n0.014\r\n\r\n\r\n73\r\n\r\n\r\n0.890\r\n\r\n\r\n0.110\r\n\r\n\r\n74\r\n\r\n\r\n0.966\r\n\r\n\r\n0.034\r\n\r\n\r\n75\r\n\r\n\r\n0.982\r\n\r\n\r\n0.018\r\n\r\n\r\n79\r\n\r\n\r\n0.992\r\n\r\n\r\n0.008\r\n\r\n\r\n80\r\n\r\n\r\n0.782\r\n\r\n\r\n0.218\r\n\r\n\r\n82\r\n\r\n\r\n0.986\r\n\r\n\r\n0.014\r\n\r\n\r\n86\r\n\r\n\r\n0.890\r\n\r\n\r\n0.110\r\n\r\n\r\n87\r\n\r\n\r\n0.974\r\n\r\n\r\n0.026\r\n\r\n\r\n90\r\n\r\n\r\n0.932\r\n\r\n\r\n0.068\r\n\r\n\r\n96\r\n\r\n\r\n0.892\r\n\r\n\r\n0.108\r\n\r\n\r\nfertilityrftestpred<-cbind(FertilityRF_Pred,FertilityTest)\r\n\r\nfertilityrftestpred<-fertilityrftestpred%>%\r\n  mutate(prediction=if_else(N>O,\"N\",\r\n                            if_else(O>N, \"O\", \"PROBLEM\")))\r\n\r\ntable(fertilityrftestpred$prediction)\r\n## \r\n##  N \r\n## 39\r\nconfusionMatrix(factor(fertilityrftestpred$prediction),factor(fertilityrftestpred$Output))\r\n## Confusion Matrix and Statistics\r\n## \r\n##           Reference\r\n## Prediction  N  O\r\n##          N 35  4\r\n##          O  0  0\r\n##                                           \r\n##                Accuracy : 0.8974          \r\n##                  95% CI : (0.7578, 0.9713)\r\n##     No Information Rate : 0.8974          \r\n##     P-Value [Acc > NIR] : 0.6290          \r\n##                                           \r\n##                   Kappa : 0               \r\n##                                           \r\n##  Mcnemar's Test P-Value : 0.1336          \r\n##                                           \r\n##             Sensitivity : 1.0000          \r\n##             Specificity : 0.0000          \r\n##          Pos Pred Value : 0.8974          \r\n##          Neg Pred Value :    NaN          \r\n##              Prevalence : 0.8974          \r\n##          Detection Rate : 0.8974          \r\n##    Detection Prevalence : 1.0000          \r\n##       Balanced Accuracy : 0.5000          \r\n##                                           \r\n##        'Positive' Class : N               \r\n## \r\nThe confusion matrix shows that the accuracy of our model is 89.7% which is pretty good for the real world.\r\nHere is a graph plotting the output based on age and alcohol consumption with several times a day, every day, several times a week, once a week, and hardly ever or never being quantified on a scale from 0 to 1. Age is quantified on a scale from 0 to 1 with 18 being 0 and 36 being 1.\r\nggplot(data=FertilityTrain)+geom_point(mapping = aes(x=AlcoholConsumption,y=Age,color=Output),alpha=0.5) + labs(color = \"Training Output\")+\r\ngeom_point(data=FertilityTest, ,mapping = aes(x=AlcoholConsumption,y=Age,shape=Output)) + labs(shape = \"Testing Output\") +\r\n  ggtitle(\"The data\")+\r\n  theme(plot.title = element_text(hjust=0.5, size=10, face='bold'))\r\n\r\nAs you can see there doesn’t seem to be a strong relationship between just these two variables and fertility. This is why it is helpful that random forest takes all the variables into account when making a classification.\r\nThis could be helpful if it could be turned into a survey of some sort women could fill out for themselves and get an idea of their fertility before spending money on doctor appointments. It wouldn’t be a surefire method but it could give them a starting point.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n// add bootstrap table styles to pandoc tables\r\nfunction bootstrapStylePandocTables() {\r\n  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');\r\n}\r\n$(document).ready(function () {\r\n  bootstrapStylePandocTables();\r\n});\r\n\r\n\r\n\r\n$(document).ready(function () {\r\n  window.buildTabsets(\"TOC\");\r\n});\r\n\r\n$(document).ready(function () {\r\n  $('.tabset-dropdown > .nav-tabs > li').click(function () {\r\n    $(this).parent().toggleClass('nav-tabs-open');\r\n  });\r\n});\r\n\r\n  (function () {\r\n    var script = document.createElement(\"script\");\r\n    script.type = \"text/javascript\";\r\n    script.src  = \"https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\";\r\n    document.getElementsByTagName(\"head\")[0].appendChild(script);\r\n  })();\r\n",
      "last_modified": "2021-12-06T11:42:39-08:00"
    },
    {
      "path": "PCA.html",
      "title": "PCA",
      "author": [],
      "contents": "\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nTaylor Wallace\r\n\r\n\r\nHome\r\nResume\r\n\r\n\r\nProjects\r\n \r\n▾\r\n\r\n\r\nRSquared\r\nMachine Learning\r\nFinal Project\r\n\r\n\r\n\r\n\r\n\r\n☰\r\n\r\n\r\n  \r\n    \r\n      \r\n        \r\n        \r\n        \r\n      \r\n      \r\n    \r\n    \r\n      \r\n  Home\r\n\r\n\r\n  Resume\r\n\r\n\r\n  \r\n    Projects\r\n     \r\n    \r\n  \r\n  \r\n      RSquared\r\n    \r\n    \r\n      Machine Learning\r\n    \r\n    \r\n      Final Project\r\n    \r\n  \r\n      \r\n  \r\n\r\n\r\n\r\n\r\n\r\n\r\nPCA\r\n\r\n\r\n\r\n\r\n\r\nPrincipcal Component Analysis (PCA)\r\nPCA is a form of dimensionality reduction used to simplify large datasets that may have useless information for what you are trying to find or predict. The algorithm uses linear algebra to test different combinations of variables to determine which ones are most important. This helps you know which variables to use for the data when using other machine learning algorithms.\r\nBelow is an example of PCA in use:\r\ndat <- iris\r\ncaret.pca <- preProcess(dat[,-5], method=\"pca\",pcaComp=2)\r\n\r\ncaret.pca\r\n## Created from 150 samples and 4 variables\r\n## \r\n## Pre-processing:\r\n##   - centered (4)\r\n##   - ignored (0)\r\n##   - principal component signal extraction (4)\r\n##   - scaled (4)\r\n## \r\n## PCA used 2 components as specified\r\ncaret.pca\r\n## Created from 150 samples and 4 variables\r\n## \r\n## Pre-processing:\r\n##   - centered (4)\r\n##   - ignored (0)\r\n##   - principal component signal extraction (4)\r\n##   - scaled (4)\r\n## \r\n## PCA used 2 components as specified\r\ndat2 <- predict(caret.pca, dat[,-5])\r\n\r\nstat.pca <- prcomp(dat[,-5],\r\n                 center = TRUE,\r\n                 scale. = TRUE)\r\n\r\nplot(stat.pca, type = \"l\")\r\n\r\nBelow shows the importance of the components:\r\nsummary(stat.pca)\r\n## Importance of components:\r\n##                           PC1    PC2     PC3     PC4\r\n## Standard deviation     1.7084 0.9560 0.38309 0.14393\r\n## Proportion of Variance 0.7296 0.2285 0.03669 0.00518\r\n## Cumulative Proportion  0.7296 0.9581 0.99482 1.00000\r\nYou can see that PC2 captures about 96% of the variance so this is the most efficient use of the variables.\r\nPCA could be useful in accounting when a client gives you a large datasets with hundreds of components. You may not have time to look through them all to determine which ones are most important, but you can simply run a PCA model and let it figure out which variables you should pay attention to.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n// add bootstrap table styles to pandoc tables\r\nfunction bootstrapStylePandocTables() {\r\n  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');\r\n}\r\n$(document).ready(function () {\r\n  bootstrapStylePandocTables();\r\n});\r\n\r\n\r\n\r\n$(document).ready(function () {\r\n  window.buildTabsets(\"TOC\");\r\n});\r\n\r\n$(document).ready(function () {\r\n  $('.tabset-dropdown > .nav-tabs > li').click(function () {\r\n    $(this).parent().toggleClass('nav-tabs-open');\r\n  });\r\n});\r\n\r\n  (function () {\r\n    var script = document.createElement(\"script\");\r\n    script.type = \"text/javascript\";\r\n    script.src  = \"https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\";\r\n    document.getElementsByTagName(\"head\")[0].appendChild(script);\r\n  })();\r\n",
      "last_modified": "2021-12-06T11:51:15-08:00"
    },
    {
      "path": "Resume.html",
      "title": "Resume",
      "author": [],
      "contents": "\r\n\r\n\r\nTAYLOR WALLACE\r\nMississippi State University\r\ntaylormwallace10@gmail.com\r\n\r\n\r\nEDUCATION\r\nMaster of Taxation & Minor in Accounting Analytics:\r\nMississippi State University, Adkerson School of Accountancy\r\nWill complete May 2022\r\nCandidate for the Uniform CPA Exam:\r\nBEC scheduled for 1/19/22\r\nBachelor of Accountancy, Magna Cum Laude:\r\nMississippi State University, Adkerson School of Accountancy\r\nGPA: 3.67/4.00\r\nCompleted May 2021\r\nWORK EXPERIENCE\r\nGraduate Research Assistant, MSU Office of Sponsored Projects May 2021 – Current\r\nAssemble subaward agreements and send to organizations for signatures\r\nAnswer any questions from the organizations regarding the agreements\r\nSend requests for any documents needed to complete the agreements\r\nTax Intern, Reynolds Bone & Griesbeck January – March 2021\r\nMade numerous spreadsheets and schedules to simplify tax preparation\r\nPrepared 1040, 1041, and 1065 returns\r\nPrepared clients’ workpaper files\r\nCAMPUS INVOLVEMENT\r\nBeta Gamma Sigma Business Honor Society\r\nBeta Alpha Psi Honor Society\r\nChi Omega Fraternity Phi Delta Chapter\r\nSKILLS\r\nMicrosoft Excel, Access, Word\r\nACL\r\nRStudio\r\nTableau\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T11:49:59-08:00"
    },
    {
      "path": "RSquared.html",
      "title": "Rsquared",
      "description": "You have been lied to about R-squared\n",
      "author": [],
      "contents": "\r\nIn undergrad I took a class almost completely dedicated to teaching R-squared. It is taught as a surefire statistical measure that should be relied on.\r\nR-squared measures how much variation of a dependent variable is explained by the independent variable in a regression model.\r\nIn this class we learned that R-squared should not be blindly relied on because it can be easily changed either mistakenly or purposely. People who do not know this can easily be manipulated into believing something that is not true about their data.\r\nBelow is one example of a problem with R-squared:\r\nIn R, we typically get R-squared by calling the summary function on a model object. Here’s a quick example using simulated data:\r\n\r\n\r\n# independent variable\r\nx <- 1:20 \r\n# for reproducibility\r\nset.seed(1) \r\n# dependent variable; function of x with random error\r\ny <- 2 + 0.5*x + rnorm(20,0,3) \r\n# simple linear regression\r\nmod <- lm(y~x)\r\n# request just the r-squared value\r\nsummary(mod)$r.squared \r\n\r\n\r\n[1] 0.6026682\r\n\r\nOne way to express R-squared is as the sum of squared fitted-value deviations divided by the sum of squared original-value deviations:\r\n\\[R^{2} =  \\frac{\\sum (\\hat{y} – \\bar{\\hat{y}})^{2}}{\\sum (y – \\bar{y})^{2}}\\]\r\nWe can calculate it directly using our model object like so:\r\n\r\n\r\n# extract fitted (or predicted) values from model\r\nf <- mod$fitted.values\r\n# sum of squared fitted-value deviations\r\nmss <- sum((f - mean(f))^2)\r\n# sum of squared original-value deviations\r\ntss <- sum((y - mean(y))^2)\r\n# r-squared\r\nmss/tss  \r\n\r\n\r\n[1] 0.6026682\r\n\r\nR-squared does not measure goodness of fit. It can be arbitrarily low when the model is completely correct. By making \\[σ^2\\] large, we drive R-squared towards 0, even when every assumption of the simple linear regression model is correct in every particular.\r\n\r\n\r\nr2.0 <- function(sig){\r\n  # our predictor\r\n  x <- seq(1,10,length.out = 100)   \r\n  # our response; a function of x plus some random noise\r\n  y <- 2 + 1.2*x + rnorm(100,0,sd = sig) \r\n  # print the R-squared value\r\n  summary(lm(y ~ x))$r.squared          \r\n}\r\n\r\nsigmas <- seq(0.5,20,length.out = 20)\r\n # apply our function to a series of sigma values\r\nrout <- sapply(sigmas, r2.0)            \r\nplot(rout ~ sigmas, type=\"b\")\r\n\r\n\r\n\r\n\r\nR-squared tanks hard with increasing sigma, even though the model is completely correct in every respect.\r\nA solution to this problem would be finding the R-squared with different values of sigmas to see how it affects it. If the change in sigmas causes a big change in R-squared, I would switch to a different measure of goodness of fit.\r\n\r\n\r\n\r\n",
      "last_modified": "2021-12-06T11:50:42-08:00"
    },
    {
      "path": "tobi.html",
      "title": "mfeo",
      "description": "mfeo\n",
      "author": [],
      "contents": "\r\nI am a classically trained data scientist living in the San Francisco Bay Area. Currently I work on the Oculus team at Facebook. I love talking about baseball, true crime podcasts, and causal inference.\r\n\r\n\r\nlibrary(distill)\r\nlibrary(postcards)\r\ncreate_theme(\"postcards\")\r\n\r\n\r\nv Created CSS file at postcards.css \r\no TODO: Customize it to suit your needs \r\no TODO: Add 'theme: postcards.css' to your site or article YAML\r\n \r\nSee docs at https://rstudio.github.io/distill/website.html#theming\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2021-10-27T09:59:45-07:00"
    }
  ],
  "collections": []
}
